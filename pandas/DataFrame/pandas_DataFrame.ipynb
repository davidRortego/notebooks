{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Data Analysis Using Jupyter Notebook\n",
    "\n",
    "## Ch. 4: Creating Thy First `pandas` DataFrame \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This here is an introduction to `pandas` DataFrames and my notes from the excellent book *Practical Data Analysis Using Jupyter Notebook*.  Please enjoy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics\n",
    "* Techniques for manipulating tabular data\n",
    "* Understanding pandas and DataFrames\n",
    "* Handling essential data formats\n",
    "* Data dictionaries and data types\n",
    "* Creating your first DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Techniques for manipulating tabular data\n",
    "\n",
    "The `pandas` Python library name was taken from the term **panel data** (by McKinney) by shortening and combining the terms to get pan and da. Panel data is defined as observations that can be measured over a period of time with multiple dimensional values and is very common in statistical studies and research papers.\n",
    "\n",
    "Panel data is presented in tabular form with rows and columns and comes in a few different types, such as balanced, unbalanced, long, short, fixed, and rotating.\n",
    "\n",
    "![Panel Data](../data/source/panel_data.JPG)\n",
    "\n",
    "Imagine, if you will, we had a summary cross table like this :\n",
    "\n",
    "![Panel Data](../data/source/begin_table.JPG)\n",
    "\n",
    "but what if we had 100 cities and it went back 10 years?  Increasing the number of columns would make this very hard to navigate.\n",
    "\n",
    "A best practice in data analysis is to begin with the end in mind. So, for this example, the output table we want to produce will look similar to the following table:\n",
    "\n",
    "![final_table](../data/source/final_table.JPG)\n",
    "\n",
    "From the preceding output, we can see that:\n",
    "\n",
    "* The first advantage of having data structured similar to the way it is in the preceding output table is that there is a single conformed data type for each column, which is also known as a dimension or axis.\n",
    "* The second advantage is that it becomes much easier for statistical analysis to be carried out because each dimension can be treated as an independent array of values of the same data type where calculations can be performed using NumPy.\n",
    "* The third advantage is the ability to sort by any field in the table without worrying about the data values in each row/tuple becoming misaligned or inconsistent.\n",
    "* Keeping the integrity of your data builds trust in your process and ensures your analysis will be accurate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding `pandas` and DataFrames\n",
    "\n",
    "A `pandas` DataFrame is defined as a two-dimensional, size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns). A DataFrame is a two-dimensional data structure—that is, data is aligned in a tabular fashion in rows and columns. A `pandas` DataFrame consists of three principal components: the data, the rows, and the columns.\n",
    "\n",
    "Some key benefits of using DataFrames include the following :\n",
    "* It allows you to convert all source files into readable data objects for easier merging and analysis.\n",
    "\n",
    "* It provides auto- or defined indexing to help with looking up a value or selecting a cross selection from your DataFrame, which is also known as a data slice.\n",
    "* Each column can be treated as a single NumPy array, which can collectively have multiple data types.\n",
    "* It really excels at fixing data alignment and missing data elements, which are displayed and referenced as Not a Number (NaN).\n",
    "* It allows pivoting and reshaping data without going back to the source of record for each dataset.\n",
    "* It is easy to add, remove, or change data using single Python commands to expedite the analysis of one or more data sources.\n",
    "* Allows aggregations, such as Group By, and other calculations against metrics, such as sum, min, max, can all be performed against the DataFrame.\n",
    "* Allows merging, sorting, joining, and filtering against one or more DataFrames.\n",
    "\n",
    "What I enjoy about using pandas and DataFrames is the flexibility of the built-incommands that are provided to you as a data analyst. Let's walk through a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a bit of test data in a dict\n",
    "product_data = {\n",
    " 'product a': [13, 20, 0, 10],\n",
    " 'project b': [10, 30, 17, 20],\n",
    " 'project c': [6, 9, 10, 0]\n",
    "}\n",
    "\n",
    "# creating a dataframe\n",
    "purchase_data = pd.DataFrame(product_data)\n",
    "purchase_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling essential data formats\n",
    "\n",
    "Source files can come in multiple formats, including :\n",
    "\n",
    "* CSV\n",
    "* JSON\n",
    "* XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data hierarchy\n",
    "\n",
    "Data hierarchies are defined and consistent groupings of data fields or records. The hierarchy can be obvious—for example, a son has a father and a mother—but from a data perspective, that relationship must be defined. In XML file format, you use a concept called an XML tree.\n",
    "\n",
    "This hierarchy relationship is commonly known as a parent-child relationship.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data dictionaries and data types\n",
    "\n",
    "A data dictionary will come in all shapes and sizes. This means it could be documented outside the source file, which is common on a help page, a wiki, or a blog or within the source data (JSON, XML)\n",
    "\n",
    "Remember that you may need to convert a data type between multiple sources, especially when blending between different systems and file formats. For example, in JSON, a number defined as `real` would be called `float` in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating thy first DataFrame\n",
    "\n",
    "Here are a couple useful commands to run in `pandas` :\n",
    "\n",
    "* `pd.read_csv(‘inport_filename.csv', header=1)` : Reads data from a CSV file directly into a pandas DataFrame\n",
    "* `my_df.to_csv(‘export_filename')` : Directly exports the DataFrame to a CSV file to your workstation (with the click of a mouse!)\n",
    "* `my_df.shape` : Provides the number of rows and columns of your DataFrame\n",
    "* `my_df.info()` : Provides metadata about your DataFrame, including data types for each column\n",
    "* `my_df.describe()` : Includes statistical details with a column that includes the count, mean, standard deviation, min, max, and percentiles (25th, 50th, and 75th) for any numeric column\n",
    "* `my_df.head(2)` : Displays the first two records from the DataFrame\n",
    "* `my_df.tail(2)` : Displays the last two records from the DataFrame\n",
    "* `my_df.sort_index(1)` : Sorts by the labels along an axis—in this example, by the column label headers alphabetically from left to right\n",
    "* `my_df.isnull()` : Displays a list of all rows with a True/False indicator if any of the values by column are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV example\n",
    "df = pd.read_csv('../data/source/evolution_of_data_analysis.csv', header=0, sep=\"|\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Q: How many milestone events occurred by decade?\n",
    "\n",
    " To answer this question, we need to use the `groupby` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decade</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1940s</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950s</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960s</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970s</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980s</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990s</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000s</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010s</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Year\n",
       "Decade      \n",
       "1940s      2\n",
       "1950s      2\n",
       "1960s      1\n",
       "1970s      2\n",
       "1980s      5\n",
       "1990s      9\n",
       "2000s     14\n",
       "2010s      7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/source/evolution_of_data_analysis.csv', header=0, sep=\"|\")\n",
    "df.groupby(['Decade']).agg({'Year': 'count'}) # what is agg?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b629c3126b5df0b3c19ac5f524890cb3a3a2e86c1a2f2c4b1c29287aa73e65d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
